{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcxEchk4ackkWsbQ1aY/lZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superspray/KOR_DA_2021/blob/main/KOR_DA_2021_DA_cMLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 조건부 MLM 기반의 데이터 증강 (DA-cMLM)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   사전학습 언어모형에 대해 MLM 과제를 학습시켜 증강에 활용함\n",
        "*   이 때 학습데이터를 클래스별로 분리하여 각각 모형을 학습시킴으로써 Finetuning 과정에서 기존 데이터의 클래스 정보를 반영할 수 있도록 함\n",
        "*  분류 성능을 평가하기 위한 지표로는 Micro-F1 및 Macro-F1 점수를 사용\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1sU6wZyd23O4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7P9wzHv0LE"
      },
      "source": [
        "# HuggingFace transformers 설치 및 NSMC 데이터셋 다운로드\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "!pip install konlpy\n",
        "!pip install selenium\n",
        "!pip install scikit-multilearn --upgrade\n",
        "\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
        "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
        "!git clone https://github.com/kocohub/korean-hate-speech\n",
        "!git clone https://github.com/songys/Toxic_comment_data\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from transformers import ElectraForMaskedLM, BertForMaskedLM\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/content/drive/MyDrive/논문/util/')\n",
        "import train_final as tr_final\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from sklearn.utils import shuffle\n",
        "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
        "from transformers import ElectraForMaskedLM, BertForMaskedLM\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import *\n",
        "from bert_cls import train_model\n",
        "from bert_cls import evaluate\n",
        "\n",
        "# GPU 사용\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# colab에서 selenium을 돌리기 위한 옵션들\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
        "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@&*[\\\\]^_`{|}~\"\n",
        "inputs = tokenizer(\n",
        "        punct,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        pad_to_max_length=True,\n",
        "        add_special_tokens=True\n",
        "        )\n",
        "# print(\"Tokens (str) : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in inputs['input_ids'].tolist()[0]]))\n",
        "punct_ids=inputs['input_ids'][0][:37].tolist()\n",
        "punct_ids.append(1)\n",
        "\n",
        "\n",
        "def sampling_func(data, sample_pct, seed = 123):\n",
        "\n",
        "    N = len(data)\n",
        "\n",
        "    data.reset_index(drop = True, inplace = True)\n",
        "    if sample_pct <= 1 :\n",
        "        sample_n = int(len(data)*sample_pct) # integer\n",
        "    else:\n",
        "        sample_n = int(sample_pct)\n",
        "\n",
        "    sample = shuffle(data, random_state = seed,  n_samples = sample_n)\n",
        "\n",
        "    return sample\n",
        "\n",
        "class NSMCDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data_file, label, sample_seed = 123, train_doc = 'document', csv_file = None, full = True, data_sep=',',\n",
        "               data_ratio = 1, mask_ratio=0.2, seed = 100, label_text = ['부정', '긍정'], punct_ids = punct_ids, #josa_ids = JOSA_ids,\n",
        "               prepend = False, toxic = False):\n",
        "    self.data_ratio = data_ratio\n",
        "    if full:\n",
        "        self.data = data_file\n",
        "    else:\n",
        "        self.data = pd.read_csv(csv_file, sep=data_sep).loc[:,[\"id\", train_doc, label]].dropna(axis=0)\n",
        "    self.data.drop_duplicates(subset=[train_doc], inplace=True)\n",
        "    self.label = label\n",
        "    self.train_doc = train_doc\n",
        "\n",
        "    self.dataset = pd.DataFrame()\n",
        "\n",
        "    if toxic:\n",
        "      for lab in self.data[self.label].unique():\n",
        "        n_sample = int(toxic_size[toxic_size.cls == lab][data_ratio].item())\n",
        "        temp = sampling_func(self.data[self.data[self.label] == lab], n_sample, sample_seed)\n",
        "        self.dataset = pd.concat([self.dataset, temp], axis = 0).reset_index(drop = True)\n",
        "\n",
        "    else:\n",
        "      for lab in self.data[self.label].unique():\n",
        "          temp = sampling_func(self.data[self.data[self.label] == lab], data_ratio, sample_seed)\n",
        "          self.dataset = pd.concat([self.dataset, temp], axis = 0).reset_index(drop = True)\n",
        "\n",
        "    # print(self.dataset[self.label].value_counts())\n",
        "    self.seed = seed\n",
        "    # self.tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-small-v2-discriminator\")\n",
        "    self.mask_ratio = mask_ratio\n",
        "    self.label_text = label_text\n",
        "    self.punct_ids = punct_ids\n",
        "    # self.josa_ids = josa_ids\n",
        "    self.prepend = prepend\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.dataset.iloc[idx, :]#.values\n",
        "    id = row['id']\n",
        "    return id"
      ],
      "metadata": {
        "id": "daSMRlQgANJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NSMC Dataset - dataloader & 모형 학습 및 성능 측정"
      ],
      "metadata": {
        "id": "o8cRkUe_EkK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "def train_model1(model, path, device, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, patience = 5):\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5,\n",
        "                    eps = 1e-8\n",
        "                    )\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "    print(\"Start training...\\n\")\n",
        "\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True, path = path)\n",
        "\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss() # Multi class\n",
        "\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        total_loss, batch_loss, batch_counts, train_accuracy = 0, 0, 0, []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            batch_counts +=1\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs= model(b_input_ids,\n",
        "                            # token_type_ids=None,\n",
        "                            attention_mask=b_attn_mask,\n",
        "                            # labels = b_labels)\n",
        "                            labels=b_labels.float())#.to(torch.float64))\n",
        "            loss = outputs[0]\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            logits = outputs[1]\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        if evaluation == True:\n",
        "\n",
        "            val_loss, val_accuracy = evaluate1(model, val_dataloader, device)[:2]\n",
        "\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        else:\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {'-':^10}| {'-':^10}| {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "        early_stopping(val_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        ".\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate1(model, val_dataloader, device, test_mode = False):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    all_logits = []\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)[0].cpu()\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits.reshape(-1) , b_labels.cpu().reshape(-1) )\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        p_exp = np.exp(logits)/(1+np.exp(logits))\n",
        "        preds = np.array(p_exp.cpu().detach()) >= 0.5 # for multi label\n",
        "        # Calculate the accuracy rate\n",
        "\n",
        "        accuracy = metrics.f1_score(b_labels.cpu().reshape(-1) , preds.reshape(-1) , average='micro')\n",
        "        val_accuracy.append(accuracy)\n",
        "        outputs.append(preds.reshape(-1) )\n",
        "        targets.append(b_labels.cpu().reshape(-1) )\n",
        "\n",
        "    outputs = np.concatenate(outputs)\n",
        "    targets = np.concatenate(targets)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    micro_f1 = metrics.f1_score(outputs, targets, average= \"micro\")\n",
        "    macro_f1 = metrics.f1_score(outputs, targets, average= \"macro\")\n",
        "\n",
        "    if test_mode:\n",
        "        print(metrics.classification_report(outputs, targets, digits=3))\n",
        "        print(\"Micro F1 score: {0:.3f}\".format(metrics.f1_score(outputs, targets, average=\"micro\")))\n",
        "        print(\"Macro F1 score: {0:.3f}\".format(metrics.f1_score(outputs, targets, average=\"macro\")))\n",
        "\n",
        "    return val_loss, micro_f1, macro_f1\n",
        "\n",
        "\n",
        "def final1(train, test, path, model, device, train_label= 'document', test_label='comments', epochs = 2, data_type = \"beep_hate\"):\n",
        "    train_data, validation_data, train_dataloader, validation_dataloader, test_dataloader = \\\n",
        "    \tdata_loader1(train, test, train_label=train_label, test_label=test_label, data_type = data_type)\n",
        "\n",
        "    set_seed(42)\n",
        "    t0 = time.time()\n",
        "    model_trained = train_model1(model, path, device, train_dataloader, validation_dataloader, epochs=epochs, evaluation = True)\n",
        "    test_result = evaluate1(model_trained, test_dataloader, device, test_mode =  True)\n",
        "\n",
        "    print(\"Loss: {0:.3f}\".format(test_result[0]))\n",
        "    print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    full_result = test_result[0], test_result[1], model\n",
        "\n",
        "    return test_result # val_loss, micro_f1, macro_f1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oXU2WEX1ANL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BEEP Dataset - dataloader & 모형 학습 및 성능 측정\n"
      ],
      "metadata": {
        "id": "R_AdQ1o_E3nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For BEEP\n",
        "def train_model2(model, path, device, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, patience = 5):\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5,\n",
        "                    eps = 1e-8\n",
        "                    )\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "    print(\"Start training...\\n\")\n",
        "\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True, path = path)\n",
        "\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        total_loss, batch_loss, batch_counts, train_accuracy = 0, 0, 0, []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            batch_counts +=1\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs= model(b_input_ids,\n",
        "                            # token_type_ids=None,\n",
        "                            attention_mask=b_attn_mask,\n",
        "                            # labels = b_labels)\n",
        "                            labels=b_labels.to(torch.float64))\n",
        "            loss = outputs[0]\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            logits = outputs[1]\n",
        "            preds = np.array(logits.cpu().detach()) >= torch.argmax(logits.cpu()).item()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        # avg_train_acc =  np.mean(train_accuracy)\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        if evaluation == True:\n",
        "\n",
        "            val_loss, val_accuracy = evaluate2(model, val_dataloader, device)[:2]\n",
        "\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        else:\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {'-':^10}| {'-':^10}| {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "        early_stopping(val_loss, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate2(model, val_dataloader, device, test_mode = False):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    all_logits = []\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss() #\n",
        "\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)[0]#.cpu()\n",
        "\n",
        "        loss = loss_fn(logits, torch.argmax(b_labels.to(torch.float64).long(),1).reshape(-1) )\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        preds = torch.argmax(logits.cpu().detach(),1).reshape(-1)\n",
        "\n",
        "        accuracy = metrics.f1_score(torch.argmax(b_labels.cpu(),1).reshape(-1) , preds, average='micro')\n",
        "        val_accuracy.append(accuracy)\n",
        "        outputs.append(preds)\n",
        "        targets.append(torch.argmax(b_labels.cpu(),1).reshape(-1))\n",
        "\n",
        "\n",
        "    outputs = np.concatenate(outputs)\n",
        "    targets = np.concatenate(targets)\n",
        "\n",
        "    val_loss = np.mean(val_loss)\n",
        "    micro_f1 = metrics.f1_score(outputs, targets, average= \"micro\")\n",
        "    macro_f1 = metrics.f1_score(outputs, targets, average= \"macro\")\n",
        "\n",
        "    if test_mode:\n",
        "        print(metrics.classification_report(outputs, targets, digits=3))\n",
        "        print(\"Micro F1 score: {0:.3f}\".format(metrics.f1_score(outputs, targets, average=\"micro\")))\n",
        "        print(\"Macro F1 score: {0:.3f}\".format(metrics.f1_score(outputs, targets, average=\"macro\")))\n",
        "\n",
        "    return val_loss, micro_f1, macro_f1\n",
        "\n",
        "\n",
        "\n",
        "def final2(train, test, path, model, device, train_label= 'document', test_label='comments', epochs = 2, data_type = \"beep_hate\"):\n",
        "    train_data, validation_data, train_dataloader, validation_dataloader, test_dataloader = \\\n",
        "    \tdata_loader2(train, test, train_label=train_label, test_label=test_label, data_type = data_type)\n",
        "\n",
        "    set_seed(42)\n",
        "    t0 = time.time()\n",
        "    model_trained = train_model2(model, path, device, train_dataloader, validation_dataloader, epochs=epochs, evaluation = True)\n",
        "    test_result = evaluate2(model_trained, test_dataloader, device, test_mode =  True)\n",
        "\n",
        "    # print(\"\")\n",
        "    # print(\"Accuracy: {0:.3f}\".format(test_result[1]))\n",
        "    print(\"Loss: {0:.3f}\".format(test_result[0]))\n",
        "    print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    full_result = test_result[0], test_result[1], model\n",
        "\n",
        "    return test_result # val_loss, micro_f1, macro_f1\n",
        "\n"
      ],
      "metadata": {
        "id": "WFC0agglANPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}